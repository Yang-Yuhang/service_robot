<launch>
    <!--start usb camera -->
    <node 
        name="usb_cam" 
        pkg="usb_cam" 
        type="usb_cam_node" 
        output="screen" 
        >
        <param name="video_device" value="/dev/video0" />
        <param name="image_width" value="640" />
        <param name="image_height" value="480" />
        <param name="pixel_format" value="yuyv" />
        <param name="camera_frame_id" value="usb_cam" />
        <param name="io_method" value="mmap"/>
    </node>

    <!--initialize face_recognition node -->
    <arg name="launch_face_detection" default="true" />
    

    <arg name="use_opencv3" default="false" />
    <arg name="use_opencv3_1" default="false" />
    <arg name="use_opencv3_2" default="false" />
    <arg name="use_opencv3_3" default="false" />

    <arg name="use_camera_info" default="false" doc="Indicates that the camera_info topic should be subscribed to to get the default input_frame_id. Otherwise the frame from the image message will be used." />
    <arg name="debug_view" default="true" />
    <arg name="queue_size" default="100" doc="Specigy queue_size of input image subscribers" />

    <arg name="image" default="/usb_cam/image_raw" />
    <arg name="data_dir" default="~/.ros/opencv_apps/face_data" />

    <include file="$(find opencv_apps)/launch/face_detection.launch"
             if="$(arg launch_face_detection)">
      <arg name="use_camera_info" value="$(arg use_camera_info)" />
      <arg name="image" value="$(arg image)" />
      <arg name="debug_view" value="$(arg debug_view)" />
      <arg name="node_name" value="face_detection" />
      <arg name="use_opencv3" value="$(arg use_opencv3)" />
      <arg name="use_opencv3_1" value="$(arg use_opencv3_1)" />
      <arg name="use_opencv3_2" value="$(arg use_opencv3_2)" />
      <arg name="use_opencv3_3" value="$(arg use_opencv3_3)" />
    </include>

    <node name="face_recognition" pkg="opencv_apps" type="face_recognition"
          output="screen">
      <param name="data_dir" value="$(arg data_dir)" />
      <param name="queue_size" value="$(arg queue_size)" />
      <remap from="image" to="$(arg image)" />
      <remap from="faces" to="face_detection/faces" />
    </node>


    <node name="$(anon debug_image_viewer)" pkg="image_view" type="image_view"
          if="$(arg debug_view)">
      <remap from="image" to="face_recognition/debug_image" />
    </node>



    
    <!--initialize cam_shift node -->
    <!--
    <arg name="node_name2" default="camshift" />
    <arg name="histogram" default="[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 255.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]" doc="Histogram of tracked color object" />
    <arg name="vmin" default="10" doc="Min threshould of lightness."/>
    <arg name="vmax" default="230" doc="Max threshould of lightness." />
    <arg name="smin" default="60" doc="Min value of saturation." />
    -->

    <!-- camshift.cpp -->
    <!--
    <node name="$(arg node_name2)" pkg="opencv_apps" type="camshift" >
      <remap from="image" to="$(arg image)" />
      <param name="use_camera_info" value="$(arg use_camera_info)" />
      <param name="debug_view" value="$(arg debug_view)" />
      <param name="queue_size" value="$(arg queue_size)" />
      <rosparam param="histogram" subst_value="True">
        $(arg histogram)
      </rosparam>
      <param name="vmin" value="$(arg vmin)" />
      <param name="vmax" value="$(arg vmax)" />
      <param name="smin" value="$(arg smin)" />
    </node>
    -->

    <!--start speech model -->
    <!-- Args with no default attribute are not optional -->
    <arg name="input" default=":default"/>
    <arg name="hmm" default=":default"/>
    <arg name="dict" default="/home/yyh/robotics_ws/src/rc-home-edu-learn-ros/rchomeedu_homework/database/homeparty.dic"/>
    <arg name="lm" default="/home/yyh/robotics_ws/src/rc-home-edu-learn-ros/rchomeedu_homework/database/homeparty.lm"/>
    <arg name="gram" default=":default"/>
    <arg name="grammar" default=":default"/>
    <arg name="rule" default=":default"/>
    
    <!--Node for handling lm mode-->
	<node
		name="lm_control"
		pkg="rchomeedu_speech"
		type="lm_test.py"
        output="screen"
        >
        <remap from="jsgf_audio" to="sphinx_audio" />
        <param name="lm" value="$(arg lm)"/>
        <param name="dict" value="$(arg dict)"/>
        <param name="hmm" value="$(arg hmm)"/>
        <param name="gram" value="$(arg gram)"/>
        <param name="grammar" value="$(arg grammar)"/>
        <param name="rule" value="$(arg rule)"/>
	</node>

    <!--Node for publishing audio inputs-->
    <node
        name="audio_control"
        pkg="pocketsphinx"
        type="send_audio.py"
        output="screen"
        >
        <param name="input" value="$(arg input)"/>
    </node>


    <node name="soundplay_node" pkg="sound_play" type="soundplay_node.py"/>
    <node name="talkbot" pkg="rchomeedu_homework" type="home_party.py" output="screen"/>
    <node name="take_photo" pkg="rchomeedu_homework" type="take_photo.py"/>
    <node name="navi_point" pkg="rchomeedu_homework" type="navigation5.py" output="screen"/>
    
</launch>

